{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aajUF3PwffdI"
      },
      "source": [
        "If you're running this jupyter notebook in a Google Colab please uncomment lines and run this cell.\n",
        "Otherwise ignore it since the files will be available to you locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rvSl5jjcxt4"
      },
      "outputs": [],
      "source": [
        "# !wget -P data/ https://raw.githubusercontent.com/paramm-team/data_processing/main/src/input/data/Digatron.csv\n",
        "# !wget -P data/ https://raw.githubusercontent.com/paramm-team/data_processing/main/src/input/data/Gamry.DTA\n",
        "# !wget -P data/ https://raw.githubusercontent.com/paramm-team/data_processing/main/src/input/data/Maccor.csv\n",
        "# !wget -P data/ https://raw.githubusercontent.com/paramm-team/data_processing/main/src/input/data/Novonix.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySRoDzepU9bU"
      },
      "source": [
        "When you execute this command in a Jupyter Notebook, pip will clone the data_processing repository from GitHub and install it into your Python environment. This method of installation is often used for packages that are in development or when you want to install a specific version of a package that is not available through PyPI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJOzLCEkScmK"
      },
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/paramm-team/data_processing.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqkFBpF7V_RR"
      },
      "source": [
        "The line import src in a Jupyter Notebook is a Python statement that imports a module named src into the current namespace, allowing you to use its functions, classes, and variables within your notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qsWt6DozWsY7"
      },
      "outputs": [],
      "source": [
        "import pbdp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0EGeigSWOYH"
      },
      "source": [
        "The result of this function call will be a string that represents the path to the data directory. This path will be platform-independent, meaning it will use the correct path separators for Unix (/) or Windows (\\\\).\n",
        "\n",
        "**Files available in this folder for testing purposes are: Digatron.csv, Maccor.csv, Novonix.csv, Gamry.DTA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kTA1hDMI71JF",
        "outputId": "b9ebb056-8dd2-44dd-8a7d-a94e5795daae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/input/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import platform\n",
        "from pathlib import Path\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    path = Path('data/').absolute()\n",
        "else:\n",
        "    path = Path(pbdp.__path__[0], \"input\", \"data\").absolute()\n",
        "    print(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jojZEIcoWp6e"
      },
      "source": [
        "**The following example contains the maximum you could achieve using the data_importer method which returns a dataframe. For a more simpler approach please find an example below and there will be a breakdown for each options separately with an example.**\n",
        "\n",
        "parser = src.Parser(): This line creates an instance of the Parser class from the src package.\n",
        "\n",
        "**path_or_file**='/usr/local/lib/python3.10/dist-packages/src/input/data/Digatron.csv': This is the path to the file that the data_importer method will process. If you are not using Google Colab, adjust this option with the result from the above and the filename as in the example.\n",
        "\n",
        "**print_option**=\"diff\": This is the custom-made plotting functionality of the package. It creates interactive plots for Current, Voltage, Temperature, Steps over time.\n",
        "\n",
        "**file_type**='csv': This indicates the type of the file being saved is CSV. Other options are: parquet, pickle, and feather\n",
        "\n",
        "**save_option**=\"save all\": This is instructing the data_importer method to save all the processed data, including the metadata separatelly from the pre-processed data. If you want to save onlly the data itself, remove this option.\n",
        "\n",
        "**state_option**=\"yes\": This will be the simplest form of data processing that the package is able to achieve. It will add a column to your data named \"Battery State\" which will say at every row the battery is either, charging, discharging, or resting. If you don't require this just remove the option."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6bbjouXytO9C",
        "outputId": "080ababc-be98-4bb9-a6ef-050dd48025cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/pbdp_parser.py:381: DtypeWarning: Columns (0,2,3,4,5,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(temp_file, encoding=encoding)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Step Number Status Step Time  Time [s] Cycle Cycle Level  \\\n",
            "0          1.0    PAU     0.008     0.064     0           0   \n",
            "1          1.0    PAU     1.010     1.066     0           0   \n",
            "2          1.0    PAU     2.028     2.084     0           0   \n",
            "3          1.0    PAU     3.031     3.087     0           0   \n",
            "4          1.0    PAU     4.056     4.112     0           0   \n",
            "5          1.0    PAU     5.018     5.074     0           0   \n",
            "6          1.0    PAU     6.025     6.081     0           0   \n",
            "7          1.0    PAU     7.083     7.139     0           0   \n",
            "8          1.0    PAU     8.067     8.123     0           0   \n",
            "9          1.0    PAU     9.057     9.113     0           0   \n",
            "\n",
            "              Procedure  Voltage [V]  Current [A]  AmpHrs [Ah]   AhPrev  \\\n",
            "0  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "1  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "2  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "3  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "4  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "5  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "6  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "7  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "8  LTA_LG50_RPT_Ext_All      3.11756          0.0          0.0  0.00000   \n",
            "9  LTA_LG50_RPT_Ext_All      3.11767          0.0          0.0  0.00000   \n",
            "\n",
            "   WattHrs [Wh]     Watt  Temperature [degC] Battery State  \n",
            "0           0.0  0.00000                25.0          rest  \n",
            "1           0.0  0.00000                25.0          rest  \n",
            "2           0.0  0.00000                25.0          rest  \n",
            "3           0.0  0.00000                25.0          rest  \n",
            "4           0.0  0.00000                25.0          rest  \n",
            "5           0.0  0.00000                25.0          rest  \n",
            "6           0.0  0.00000                25.0          rest  \n",
            "7           0.0  0.00000                25.0          rest  \n",
            "8           0.0  0.00000                25.0          rest  \n",
            "9           0.0  0.00000                25.0          rest  \n",
            "An error occurred: Mime type rendering requires nbformat>=4.2.0 but it is not installed in file /Users/pipgrylls/Code/data_processing/pbdp/input/data/Digatron.csv\n",
            "An error occurred: Mime type rendering requires nbformat>=4.2.0 but it is not installed in file /Users/pipgrylls/Code/data_processing/pbdp/input/data/Digatron.csv\n"
          ]
        }
      ],
      "source": [
        "parser = pbdp.Parser()\n",
        "data = parser.data_importer(path_or_file=path / \"Digatron.csv\", print_option=\"diff\", file_type=\"csv\", save_option=\"save all\", state_option=\"yes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNliazf9bIUs"
      },
      "source": [
        "**This example contains the bare minimum that the method will do for you in terms of preprocessing. Save only the data from the files in a parquet, removing the metadata and adjusting the column names and units, removing empty rows and returning the final dataframe**\n",
        "\n",
        "parser = src.Parser(): This line creates an instance of the Parser class from the src package.\n",
        "\n",
        "**path_or_file**='/usr/local/lib/python3.10/dist-packages/src/input/data/': This is the path to the folder that the data_importer method will process. Put the result from the above plus / the file name inside the '' to test the package outside of Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hHfltfuy08Zt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/save.py:38: FutureWarning:\n",
            "\n",
            "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "\n",
            "/Users/pipgrylls/Code/data_processing/pbdp/save.py:38: FutureWarning:\n",
            "\n",
            "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "No keywords found in file: /Users/pipgrylls/Code/data_processing/pbdp/input/data/test1.csv",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m parser \u001b[38;5;241m=\u001b[39m pbdp\u001b[38;5;241m.\u001b[39mParser()\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_importer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Code/data_processing/pbdp/pbdp_parser.py:521\u001b[0m, in \u001b[0;36mParser.data_importer\u001b[0;34m(self, path_or_file, file_type, save_option, state_option, print_option)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03mImport, process, and optionally save and/or print battery data.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m                                    Defaults to \"\".\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlook_for_files(path_or_file):\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;66;03m# Process each file\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     pointer, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     metadata, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_file(pointer, file, save_option)\n\u001b[1;32m    523\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_data_to_pandas(data, file, encoding)\n",
            "File \u001b[0;32m~/Code/data_processing/pbdp/pbdp_parser.py:284\u001b[0m, in \u001b[0;36mParser.find_words\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (f\u001b[38;5;241m.\u001b[39mtell(), encoding)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# If no match is found, raise an exception\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo keywords found in file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: No keywords found in file: /Users/pipgrylls/Code/data_processing/pbdp/input/data/test1.csv"
          ]
        }
      ],
      "source": [
        "parser = pbdp.Parser()\n",
        "data = parser.data_importer(path_or_file=path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pwneQc2eLhZ"
      },
      "source": [
        "**This example focuses on saving options available after preprocessing**\n",
        "\n",
        "**save_option=\"\"** the available options are **\"save\"** **(default)** and **\"save all\"**. The first keeps only the data and the latter saves the metadata in a separate file in case it's needed.\n",
        "\n",
        "**file_type=\"\"** the available options are **\"parquet\" (default), \"csv\", \"feather\", and \"pickle\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NBNTCS_2eJWH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/pbdp_parser.py:381: DtypeWarning:\n",
            "\n",
            "Columns (0,2,3,4,5,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parser = pbdp.Parser()\n",
        "data = parser.data_importer(path_or_file=path / 'Digatron.csv', save_option=\"save\", file_type=\"pickle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5vwyGLjVlL"
      },
      "source": [
        " **This example focuses on displaying options available after preprocessing**\n",
        "\n",
        "**print_options=\"\"** available options are **\"yes\" or \"diff\"**. This is the custom-made plotting functionality of the package. It creates interactive plots for Current, Voltage, Temperature, Steps over Time automatically adjusting for the availability (data must record time).\n",
        "\n",
        "**\"yes\"** will be plotting up to 4 graphs mentioned and a preview of the columns and first rows of data, while **\"diff\"** will add two extra plots of Current and Voltage with the derivative (diff between points) on top for easier track of changes over time.\n",
        "\n",
        "*This method will display the graphs in Google Colab or open a browser if you're running the code locally.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vxbVhQScnqQU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/pbdp_parser.py:381: DtypeWarning:\n",
            "\n",
            "Columns (0,2,3,4,5,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n",
            "/Users/pipgrylls/Code/data_processing/pbdp/save.py:38: FutureWarning:\n",
            "\n",
            "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parser = pbdp.Parser()\n",
        "data = parser.data_importer(path_or_file=path / 'Digatron.csv', print_option=\"save\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOdGWXOdn_Cj"
      },
      "source": [
        "**This example focuses on a simple processing of Battery State based on Current**\n",
        "\n",
        "This method adds a column named \"Battery State\" which describes at every row the actions of charging, discharging or resting based on a threshold for the current values.\n",
        "\n",
        "**state_option=\"yes\"** this option is optional, hence not required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JNg10i9Jn3em"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pipgrylls/Code/data_processing/pbdp/pbdp_parser.py:381: DtypeWarning:\n",
            "\n",
            "Columns (0,2,3,4,5,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "\n",
            "/Users/pipgrylls/Code/data_processing/pbdp/save.py:38: FutureWarning:\n",
            "\n",
            "DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "parser = pbdp.Parser()\n",
        "data = parser.data_importer(path_or_file=path / \"Digatron.csv\", state_option=\"yes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
